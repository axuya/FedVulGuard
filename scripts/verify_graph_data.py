import json
import numpy as np
from pathlib import Path
from collections import Counter
import matplotlib.pyplot as plt

def analyze_graph_quality():
    """åˆ†æå›¾æ•°æ®è´¨é‡"""
    
    print("="*70)
    print("ğŸ“Š Graph Data Quality Analysis")
    print("="*70)
    
    graph_dir = Path("data/graphs")
    index_file = graph_dir / "graph_index.json"
    
    if not index_file.exists():
        print(f"âŒ Index file not found: {index_file}")
        return
    
    # åŠ è½½ç´¢å¼•
    with open(index_file, 'r') as f:
        index = json.load(f)
    
    print(f"\nğŸ“¦ Total pairs in index: {len(index)}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'ast': {'nodes': [], 'edges': []},
        'cfg': {'nodes': [], 'edges': []},
        'dfg': {'nodes': [], 'edges': []},
        'pdg': {'nodes': [], 'edges': []}
    }
    
    vuln_types = Counter()
    sloc_before = []
    sloc_after = []
    
    # åˆ†ææ¯ä¸ªå›¾æ–‡ä»¶
    valid_count = 0
    for item in index:
        pair_id = item['pair_id']
        vuln_types[item['vulnerability_type']] += 1
        
        # è¯»å– before å›¾
        before_path = Path(item['before_graphs'])
        if before_path.exists():
            try:
                with open(before_path, 'r') as f:
                    before_data = json.load(f)
                
                # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
                for graph_type in ['ast', 'cfg', 'dfg', 'pdg']:
                    g = before_data[graph_type]
                    stats[graph_type]['nodes'].append(len(g['nodes']))
                    stats[graph_type]['edges'].append(len(g['links']))
                
                sloc_before.append(before_data['metadata']['sloc'])
                valid_count += 1
                
            except Exception as e:
                print(f"âš ï¸  Error reading {before_path}: {e}")
        
        # è¯»å– after å›¾
        after_path = Path(item['after_graphs'])
        if after_path.exists():
            try:
                with open(after_path, 'r') as f:
                    after_data = json.load(f)
                sloc_after.append(after_data['metadata']['sloc'])
            except:
                pass
    
    print(f"âœ… Valid graph files: {valid_count}")
    
    # æ‰“å°ç»Ÿè®¡
    print("\n" + "="*70)
    print("ğŸ“Š Graph Statistics")
    print("="*70)
    
    for graph_type in ['ast', 'cfg', 'dfg', 'pdg']:
        nodes = stats[graph_type]['nodes']
        edges = stats[graph_type]['edges']
        
        if nodes:
            print(f"\n{graph_type.upper()}:")
            print(f"   Nodes: avg={np.mean(nodes):.1f}, "
                  f"min={min(nodes)}, max={max(nodes)}, std={np.std(nodes):.1f}")
            print(f"   Edges: avg={np.mean(edges):.1f}, "
                  f"min={min(edges)}, max={max(edges)}, std={np.std(edges):.1f}")
    
    # æ¼æ´ç±»å‹åˆ†å¸ƒ
    print("\n" + "="*70)
    print("ğŸ”– Vulnerability Type Distribution")
    print("="*70)
    for vtype, count in vuln_types.most_common():
        print(f"   {vtype:20s}: {count:3d} ({count/len(index)*100:5.1f}%)")
    
    # ä»£ç é•¿åº¦
    if sloc_before and sloc_after:
        print("\n" + "="*70)
        print("ğŸ“ Code Length (SLOC)")
        print("="*70)
        print(f"   Before: avg={np.mean(sloc_before):.1f}, "
              f"min={min(sloc_before)}, max={max(sloc_before)}")
        print(f"   After:  avg={np.mean(sloc_after):.1f}, "
              f"min={min(sloc_after)}, max={max(sloc_after)}")
    
    # è´¨é‡æ£€æŸ¥
    print("\n" + "="*70)
    print("âœ… Quality Checks")
    print("="*70)
    
    checks = []
    
    # æ£€æŸ¥1: èŠ‚ç‚¹æ•°åˆç†
    avg_nodes = np.mean(stats['ast']['nodes'])
    if avg_nodes > 10:
        checks.append(("âœ…", f"ASTèŠ‚ç‚¹æ•°åˆç† (avg={avg_nodes:.1f})"))
    else:
        checks.append(("âš ï¸ ", f"ASTèŠ‚ç‚¹æ•°åå°‘ (avg={avg_nodes:.1f})"))
    
    # æ£€æŸ¥2: è¾¹æ•°åˆç†
    avg_edges = np.mean(stats['cfg']['edges'])
    if avg_edges > 5:
        checks.append(("âœ…", f"CFGè¾¹æ•°åˆç† (avg={avg_edges:.1f})"))
    else:
        checks.append(("âš ï¸ ", f"CFGè¾¹æ•°åå°‘ (avg={avg_edges:.1f})"))
    
    # æ£€æŸ¥3: ç±»å‹è¦†ç›–
    if len(vuln_types) >= 3:
        checks.append(("âœ…", f"æ¼æ´ç±»å‹è¦†ç›–è‰¯å¥½ ({len(vuln_types)}ç§)"))
    else:
        checks.append(("âš ï¸ ", f"æ¼æ´ç±»å‹è¦†ç›–ä¸è¶³ ({len(vuln_types)}ç§)"))
    
    # æ£€æŸ¥4: æˆåŠŸç‡
    success_rate = valid_count / len(index)
    if success_rate >= 0.9:
        checks.append(("âœ…", f"å›¾æ„å»ºæˆåŠŸç‡é«˜ ({success_rate*100:.1f}%)"))
    else:
        checks.append(("âš ï¸ ", f"å›¾æ„å»ºæˆåŠŸç‡åä½ ({success_rate*100:.1f}%)"))
    
    for status, msg in checks:
        print(f"{status} {msg}")
    
    # æ¨è
    print("\n" + "="*70)
    print("ğŸ’¡ Recommendations")
    print("="*70)
    
    if success_rate >= 0.9 and avg_nodes > 20:
        print("âœ… å›¾æ•°æ®è´¨é‡ä¼˜ç§€ï¼Œå¯ä»¥è¿›å…¥ Phase 3")
        print("\nä¸‹ä¸€æ­¥:")
        print("   1. ç‰¹å¾æå–: python src/preprocessing/extract_features.py")
        print("   2. è®­ç»ƒ MGVD: python src/models/train_mgvd.py")
    elif success_rate >= 0.8:
        print("âš ï¸  å›¾æ•°æ®åŸºæœ¬å¯ç”¨ï¼Œä½†å»ºè®®æ£€æŸ¥å¤±è´¥çš„æ ·æœ¬")
        print("   å¯ä»¥ç»§ç»­ï¼Œä½†å¯èƒ½éœ€è¦è°ƒæ•´æ¨¡å‹å‚æ•°")
    else:
        print("âŒ å›¾æ•°æ®è´¨é‡ä¸è¶³ï¼Œå»ºè®®æ£€æŸ¥å¹¶ä¿®å¤")
    
    return stats, vuln_types


def visualize_sample_graph():
    """å¯è§†åŒ–ä¸€ä¸ªç¤ºä¾‹å›¾"""
    print("\n" + "="*70)
    print("ğŸ¨ Sample Graph Visualization")
    print("="*70)
    
    try:
        import networkx as nx
        
        # è¯»å–ç¬¬ä¸€ä¸ªå›¾
        graph_file = Path("data/graphs/filtered_0000_before.json")
        if not graph_file.exists():
            print("âŒ Sample graph not found")
            return
        
        with open(graph_file, 'r') as f:
            data = json.load(f)
        
        # åªå¯è§†åŒ– ASTï¼ˆæœ€ç®€å•ï¼‰
        ast_data = data['ast']
        G = nx.node_link_graph(ast_data)
        
        print(f"\nğŸ“Š Sample Graph Info:")
        print(f"   Pair: filtered_0000_before")
        print(f"   Nodes: {G.number_of_nodes()}")
        print(f"   Edges: {G.number_of_edges()}")
        print(f"   Node types: {set(nx.get_node_attributes(G, 'node_type').values())}")
        
        print("\nğŸ’¡ Tip: å¯ä»¥ä½¿ç”¨ networkx å¯è§†åŒ–:")
        print("   import networkx as nx")
        print("   import matplotlib.pyplot as plt")
        print("   nx.draw(G, with_labels=True)")
        print("   plt.show()")
        
    except ImportError:
        print("âš ï¸  networkx not available for visualization")
    except Exception as e:
        print(f"âš ï¸  Visualization error: {e}")


def main():
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘         Graph Data Quality Verification                 â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    stats, vuln_types = analyze_graph_quality()
    visualize_sample_graph()
    
    print("\n" + "="*70)
    print("ğŸ‰ Verification Complete!")
    print("="*70)


if __name__ == "__main__":
    main()