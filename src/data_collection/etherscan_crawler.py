#!/usr/bin/env python3
"""
Etherscan V2 å¤šé“¾åˆçº¦çˆ¬è™«ï¼ˆæ”¯æŒ Key æ± è½®è¯¢ + åŒºé—´æ‰«æéªŒè¯åˆçº¦ï¼‰
ä¸€é”®åå°ï¼špython etherscan_crawler.py --chain ethereum --scan --limit 10000 --batch 1000
"""

import argparse
import hashlib
import json
import logging
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

import requests
import yaml
from tqdm import tqdm

class EtherscanCrawler:
    def __init__(self, config_path: str = "configs/data_collection.yaml", chain: str = "ethereum"):
        with open(config_path, "r", encoding="utf-8") as f:
            self.config = yaml.safe_load(f)

        self.chain = chain.lower()
        self._chain_id = {
            "ethereum": "1", "bsc": "56", "polygon": "137", "avalanche": "43114"
        }
        if self.chain not in self._chain_id:
            raise ValueError(f"ä¸æ”¯æŒçš„é“¾: {chain}")

        # è¯»å–é“¾é…ç½® & åˆ‡æˆ Key æ± 
        chain_config = self.config["scan_config"]["chains"][self.chain]
        self._key_pool = [k.strip() for k in chain_config["api_key"].split(",")]
        self._key_idx = 0
        self.base_url = chain_config["api_url"]
        self.rate_limit = self.config["scan_config"]["rate_limit"]
        self.retry_attempts = self.config["scan_config"]["retry_attempts"]
        self.retry_delay = self.config["scan_config"]["retry_delay"]

        # è¾“å‡ºæŒ‰é“¾åˆ†æ–‡ä»¶å¤¹
        self.output_dir = Path(self.config["output"]["etherscan_raw"]) / self.chain
        self.output_dir.mkdir(parents=True, exist_ok=True)

        self._setup_logging()
        self.logger.info(f"Etherscan V2 çˆ¬è™«åˆå§‹åŒ– | é“¾: {self.chain.upper()} | Keys: {len(self._key_pool)}")

    # ---------------- æ—¥å¿— ----------------
    def _setup_logging(self):
        log_dir = Path(self.config["output"]["logs"])
        log_dir.mkdir(parents=True, exist_ok=True)
        logging.basicConfig(
            level=getattr(logging, self.config["logging"]["level"].upper()),
            format=self.config["logging"]["format"],
            handlers=[
                logging.FileHandler(log_dir / "etherscan_crawler.log", encoding="utf-8"),
                logging.StreamHandler(),
            ],
        )
        self.logger = logging.getLogger(__name__)

    # ---------------- é™é€Ÿ ----------------
    def _rate_limit(self):
        elapsed = time.time() - getattr(self, "last_request_time", 0)
        if elapsed < 1.0 / self.rate_limit:
            time.sleep(1.0 / self.rate_limit - elapsed)

    # ---------------- æ ¸å¿ƒè¯·æ±‚ ----------------
    def _make_request(self, params: Dict) -> Optional[List[Dict]]:
        params["apikey"] = self._key_pool[self._key_idx]
        self._key_idx = (self._key_idx + 1) % len(self._key_pool)
        params["chainid"] = self._chain_id[self.chain]

        for attempt in range(self.retry_attempts):
            try:
                self._rate_limit()
                resp = requests.get(self.base_url, params=params, timeout=10)
                resp.raise_for_status()
                data = resp.json()

                if data.get("status") == "1":
                    return data.get("result", [])
                elif data.get("message") == "No transactions found":
                    return []
                else:
                    self.logger.warning(f"API é”™è¯¯: {data.get('message', 'Unknown')}")
                    return None
            except requests.RequestException as e:
                self.logger.warning(f"è¯·æ±‚å¤±è´¥ï¼ˆ{attempt + 1}/{self.retry_attempts}ï¼‰: {e}")
                if attempt < self.retry_attempts - 1:
                    time.sleep(self.retry_delay)
                else:
                    self.logger.error(f"é‡è¯•è€—å°½ | params: {params}")
                    return None
        return None

    # ---------------- è·å–æºç  ----------------
    def get_contract_source(self, address: str) -> Optional[Dict]:
        params = {"module": "contract", "action": "getsourcecode", "address": address}
        result = self._make_request(params)
        if result and result[0].get("SourceCode"):
            self.logger.info(f"æºç é•¿åº¦: {len(result[0]['SourceCode'])} å­—èŠ‚ | {address}")
            return result[0]
        return None

    # ---------------- åœ°å€æ¥æº 1ï¼šç¡¬ç¼–ç  ----------------
    def get_defi_contracts(self) -> List[str]:
        known = {
            "ethereum": [
                "0x7a250d5630B4cF539739dF2C5dAcb4c659F2488D", "0xE592427A0AEce92De3Edee1F18E0157C05861564",
                "0x7d2768dE32b0b80b7a3454c06BdAc94A69DDc7A9", "0x5d3a536E4D6DbD6114cc1Ead35777bAB948E3643",
                "0x9f8F72aA9304c8B593d555F12eF6589cC3A579A2", "0xbEbc44782C7dB0a1A60Cb6fe97d0b483032FF1C7",
                "0xBA12222222228d8Ba445958a75a0704d566BF2C8", "0xd9e1cE17f2641f24aE83637ab66a2cca9C378B9F",
            ],
            "bsc": [
                "0x10ED43C718714eb63d5aA57B78B54704E256024E", "0x00e65A10A1A7d8B98d0CE5085E8cDF04C1eF5261",
            ],
            "polygon": [
                "0xa5E0829CaCEd8fFDD4De3c43696c57F7D7A678ff", "0x8dFf5E27EA6b7AC08ebFdf9eB790f79EE98aB2c8",
            ],
            "avalanche": [
                "0x60aE616a2155Ee3d9A68541Ba4544862310933d4", "0x794a61358D6845594F94dc1DB02A252b5b4814aD",
            ],
        }
        addresses = known.get(self.chain, [])
        self.logger.info(f"åŠ è½½ {len(addresses)} ä¸ª {self.chain.upper()} çŸ¥ååˆçº¦åœ°å€")
        return addresses

    # ---------------- åœ°å€æ¥æº 2ï¼šåŒºé—´æ‰«æéªŒè¯åˆçº¦ ----------------
    def get_verified_contracts_by_range(self, start_block: int, end_block: int, max_addrs: int = 1000) -> List[str]:
        """
        é€šè¿‡ getLogs æ‰«æ ContractCreation äº‹ä»¶ï¼Œå†è°ƒ getsourcecode éªŒè¯æ˜¯å¦æœ‰æºç 
        é€‚åˆå…è´¹ Key ä¸‹å¤§æ‰¹é‡æ‰©å……åœ°å€æ± 
        """
        self.logger.info(f"å¼€å§‹æ‰«æåŒºå— {start_block} -> {end_block}ï¼Œæœ€å¤šå– {max_addrs} ä¸ªéªŒè¯åˆçº¦")
        addresses = []
        step = 2000   # å…è´¹ç‰ˆä¸€æ¬¡æœ€å¤š 1000 æ¡ logï¼Œä¿å®ˆ 2k åŒºå—
        for from_block in range(start_block, end_block, step):
            to_block = min(from_block + step - 1, end_block)
            # ContractCreation äº‹ä»¶ topic0ï¼ˆCreate/Create2 éƒ½ä¼šè§¦å‘ï¼‰
            params = {
                "module": "logs",
                "action": "getLogs",
                "fromBlock": from_block,
                "toBlock": to_block,
                "topic0": "0x8be0079c531659141344cd1fd0a4f28419497f9722a3daafe3b4186f6b6457e0",  # OwnershipTransferredï¼ˆåˆ›å»ºå³ ownerï¼‰
            }
            logs = self._make_request(params)
            if not logs:
                continue
            for log in logs:
                addr = log.get("address")
                if not addr:
                    continue
                # è°ƒ getsourcecode éªŒè¯æ˜¯å¦å·²éªŒè¯
                if self.get_contract_source(addr):
                    addresses.append(addr)
                    if len(addresses) >= max_addrs:
                        self.logger.info(f"å·²æ”¶é›†å¤Ÿ {max_addrs} ä¸ªéªŒè¯åˆçº¦ï¼Œæå‰ç»“æŸ")
                        return addresses
        self.logger.info(f"æ‰«æå®Œæˆï¼Œå…±å¾—åˆ° {len(addresses)} ä¸ªéªŒè¯åˆçº¦")
        return addresses

    # ---------------- æ‰¹é‡çˆ¬å– ----------------
    def crawl_contracts(self, addresses: List[str], save_batch_size: int = 100):
        self.logger.info(f"å¼€å§‹çˆ¬å– {len(addresses)} ä»½åˆçº¦")
        contracts, fails = [], []
        for i, addr in enumerate(tqdm(addresses, desc="Crawling")):
            c = self.get_contract_source(addr)
            if c and c.get("SourceCode"):
                c["crawled_at"] = datetime.now().isoformat()
                c["address"] = addr
                c["code_hash"] = hashlib.md5(c["SourceCode"].encode()).hexdigest()
                contracts.append(c)
                if (i + 1) % save_batch_size == 0:
                    self._save_batch(contracts, i // save_batch_size)
                    contracts = []
            else:
                fails.append(addr)
        if contracts:
            self._save_batch(contracts, len(addresses) // save_batch_size)
        if fails:
            (self.output_dir / "failed_addresses.json").write_text(json.dumps(fails, indent=2))
        self.logger.info(f"çˆ¬å–å®Œæˆ | æˆåŠŸ: {len(addresses) - len(fails)} | å¤±è´¥: {len(fails)}")

    def _save_batch(self, contracts: List[Dict], batch_num: int):
        batch_file = self.output_dir / f"batch_{batch_num:04d}.json"
        batch_file.write_text(json.dumps(contracts, indent=2, ensure_ascii=False))
        self.logger.info(f"å·²ä¿å­˜æ‰¹æ¬¡ {batch_num} | å…± {len(contracts)} ä»½åˆçº¦")

    # ---------------- è¿‡æ»¤ & ç»Ÿè®¡ ----------------
    def filter_contracts(self, min_lines: int = 100, max_lines: int = 5000):
        self.logger.info("å¼€å§‹è¿‡æ»¤åˆçº¦ï¼ˆä»£ç è¡Œæ•°ï¼‰")
        all_contracts = []
        for f in self.output_dir.glob("batch_*.json"):
            all_contracts.extend(json.loads(f.read_text()))
        filtered = [c for c in all_contracts if min_lines <= c["SourceCode"].count("\n") <= max_lines]
        out = Path(self.config["output"]["etherscan_processed"]) / self.chain / "filtered_contracts.json"
        out.parent.mkdir(parents=True, exist_ok=True)
        out.write_text(json.dumps(filtered, indent=2, ensure_ascii=False))
        self.logger.info(f"è¿‡æ»¤å®Œæˆ | ä¿ç•™ {len(filtered)} / {len(all_contracts)} ä»½åˆçº¦")
        return filtered

    def generate_statistics(self):
        self.logger.info("ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š")
        all_contracts = []
        for f in self.output_dir.glob("batch_*.json"):
            all_contracts.extend(json.loads(f.read_text()))
        stats = {
            "total_contracts": len(all_contracts),
            "compiler_versions": {},
            "contract_names": {},
            "avg_code_length": 0,
            "optimization_enabled": 0,
        }
        total_lines = 0
        for c in all_contracts:
            compiler = c.get("CompilerVersion", "Unknown")
            name = c.get("ContractName", "Unknown")
            lines = c["SourceCode"].count("\n")
            stats["compiler_versions"][compiler] = stats["compiler_versions"].get(compiler, 0) + 1
            stats["contract_names"][name] = stats["contract_names"].get(name, 0) + 1
            total_lines += lines
            if c.get("OptimizationUsed") == "1":
                stats["optimization_enabled"] += 1
        stats["avg_code_length"] = total_lines / len(all_contracts) if all_contracts else 0
        (self.output_dir / "statistics.json").write_text(json.dumps(stats, indent=2))
        self.logger.info(f"ç»Ÿè®¡å·²ä¿å­˜ | å¹³å‡ä»£ç è¡Œæ•°: {stats['avg_code_length']:.2f}")
        return stats


# ---------------- main ----------------
def main():
    parser = argparse.ArgumentParser(description="Etherscan V2 å¤šé“¾åˆçº¦çˆ¬è™«ï¼ˆKey æ± è½®è¯¢ + åŒºé—´æ‰«æï¼‰")
    parser.add_argument("--chain", default="ethereum", choices=["ethereum", "bsc", "polygon", "avalanche"], help="ç›®æ ‡é“¾")
    parser.add_argument("--limit", type=int, help="é™åˆ¶åœ°å€æ•°é‡ï¼ˆè°ƒè¯•ç”¨ï¼‰")
    parser.add_argument("--batch", type=int, default=1000, help="æ¯æ‰¹ä¿å­˜æ•°é‡")
    parser.add_argument("--scan", action="store_true", help="ç”¨åŒºé—´æ‰«æä»£æ›¿ç¡¬ç¼–ç ")
    parser.add_argument("--start", type=int, default=16000000, help="èµ·å§‹åŒºå—")
    parser.add_argument("--end", type=int, default=16100000, help="ç»“æŸåŒºå—")
    args = parser.parse_args()

    crawler = EtherscanCrawler(chain=args.chain)

    if args.scan:
        addresses = crawler.get_verified_contracts_by_range(
            start_block=args.start,
            end_block=args.end,
            max_addrs=args.limit or 1000
        )
    else:
        addresses = crawler.get_defi_contracts()
        if args.limit:
            addresses = addresses[:args.limit]

    print(f"\nğŸ”— é“¾: {args.chain.upper()} | å¾…çˆ¬åœ°å€: {len(addresses)}\n")
    if not addresses:
        print("âŒ åœ°å€åˆ—è¡¨ä¸ºç©º")
        exit(0)

    crawler.crawl_contracts(addresses, save_batch_size=args.batch)
    crawler.filter_contracts()
    stats = crawler.generate_statistics()
    print("\n=== ç»Ÿè®¡æ‘˜è¦ ===")
    print(f"æ€»åˆçº¦: {stats['total_contracts']}  |  å¹³å‡è¡Œæ•°: {stats['avg_code_length']:.2f}")
    print(f"å¯ç”¨ä¼˜åŒ–: {stats['optimization_enabled']}")


if __name__ == "__main__":
    main()