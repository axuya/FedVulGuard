#!/usr/bin/env python3
"""
è”é‚¦å­¦ä¹ è®­ç»ƒ - æ¨¡æ‹Ÿ 5 ä¸ªå®¢æˆ·ç«¯
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

import torch
import torch.nn as nn
import copy
import json
import numpy as np
from collections import defaultdict

# å¯¼å…¥ MGVD æ¨¡å‹
from src.models.train_mgvd import MGVDModel, load_graph_data

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


class FederatedTrainer:
    """è”é‚¦å­¦ä¹ è®­ç»ƒå™¨"""
    
    def __init__(self, num_clients=5, rounds=20):
        self.num_clients = num_clients
        self.rounds = rounds
        self.global_model = MGVDModel().to(device)
        
    def split_data_non_iid(self, data, num_clients):
        """Non-IID æ•°æ®åˆ’åˆ†"""
        # æŒ‰æ ‡ç­¾åˆ†ç»„
        label_groups = defaultdict(list)
        for item in data:
            label_groups[item['label']].append(item)
        
        # ä¸ºæ¯ä¸ªå®¢æˆ·ç«¯åˆ†é…æ•°æ®ï¼ˆä¸å¹³è¡¡ï¼‰
        client_data = [[] for _ in range(num_clients)]
        
        for label, items in label_groups.items():
            # éšæœºæ‰“ä¹±
            np.random.shuffle(items)
            
            # Dirichlet åˆ†å¸ƒæ¨¡æ‹Ÿ Non-IID
            proportions = np.random.dirichlet([0.5] * num_clients)
            splits = (np.cumsum(proportions) * len(items)).astype(int)
            
            start = 0
            for i, end in enumerate(splits):
                client_data[i].extend(items[start:end])
                start = end
        
        return client_data
    
    def local_train(self, model, data, epochs=3):
        """å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒ"""
        model.train()
        optimizer = torch.optim.SGD(model.parameters(), lr=0.01)
        criterion = nn.CrossEntropyLoss()
        
        for _ in range(epochs):
            for item in data:
                optimizer.zero_grad()
                
                graphs = item['graphs']
                label = torch.tensor([item['label']], dtype=torch.long).to(device)
                
                batch_ast = torch.zeros(graphs['ast'].x.size(0), dtype=torch.long).to(device)
                batch_cfg = torch.zeros(graphs['cfg'].x.size(0), dtype=torch.long).to(device)
                batch_dfg = torch.zeros(graphs['dfg'].x.size(0), dtype=torch.long).to(device)
                batch_pdg = torch.zeros(graphs['pdg'].x.size(0), dtype=torch.long).to(device)
                
                for g_type in graphs:
                    graphs[g_type] = graphs[g_type].to(device)
                
                out = model(graphs['ast'], graphs['cfg'], graphs['dfg'], graphs['pdg'],
                           (batch_ast, batch_cfg, batch_dfg, batch_pdg))
                loss = criterion(out, label)
                loss.backward()
                optimizer.step()
        
        return model.state_dict()
    
    def fedavg(self, client_weights, client_sizes):
        """FedAvg èšåˆ"""
        avg_weights = {}
        total_size = sum(client_sizes)
        
        for key in client_weights[0].keys():
            avg_weights[key] = sum(
                w[key] * size / total_size 
                for w, size in zip(client_weights, client_sizes)
            )
        
        return avg_weights
    
    def train(self):
        """è”é‚¦è®­ç»ƒä¸»æµç¨‹"""
        print("="*70)
        print("ğŸŒ Federated Learning Training")
        print("="*70)
        
        # åŠ è½½æ•°æ®
        print("\nğŸ“¦ Loading data...")
        index_file = Path("data/graphs/main_dataset/main_dataset_index.json")
        with open(index_file, 'r') as f:
            index = json.load(f)
        
        vuln_to_idx = {
            'reentrancy': 0, 'overflow': 1, 'access_control': 2,
            'tx_origin': 3, 'timestamp': 4, 'unchecked_call': 5, 'unknown': 6
        }
        
        dataset = []
        for item in index[:50]:  # ä½¿ç”¨ 50 ä¸ªæ ·æœ¬
            try:
                graphs = load_graph_data(item['graph_path'])
                dataset.append({
                    'graphs': graphs,
                    'label': vuln_to_idx.get(item['vulnerability_type'], 6)
                })
            except:
                pass
        
        # Non-IID åˆ’åˆ†
        print(f"ğŸ“Š Splitting data into {self.num_clients} clients (Non-IID)...")
        client_datasets = self.split_data_non_iid(dataset, self.num_clients)
        
        for i, data in enumerate(client_datasets):
            print(f"   Client {i}: {len(data)} samples")
        
        # è”é‚¦è®­ç»ƒ
        print(f"\nğŸ”¥ Starting {self.rounds} rounds of federated training...")
        
        for round_idx in range(self.rounds):
            print(f"\n--- Round {round_idx + 1}/{self.rounds} ---")
            
            client_weights = []
            client_sizes = []
            
            # æ¯ä¸ªå®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒ
            for client_id in range(self.num_clients):
                # å¤åˆ¶å…¨å±€æ¨¡å‹
                local_model = copy.deepcopy(self.global_model)
                
                # æœ¬åœ°è®­ç»ƒ
                weights = self.local_train(
                    local_model, 
                    client_datasets[client_id],
                    epochs=3
                )
                
                client_weights.append(weights)
                client_sizes.append(len(client_datasets[client_id]))
            
            # èšåˆ
            global_weights = self.fedavg(client_weights, client_sizes)
            self.global_model.load_state_dict(global_weights)
            
            # è¯„ä¼°
            if (round_idx + 1) % 5 == 0:
                acc = self.evaluate(dataset[:10])
                print(f"   Global Model Accuracy: {acc:.4f}")
        
        # ä¿å­˜æ¨¡å‹
        torch.save(self.global_model.state_dict(), 'models/federated_model.pth')
        print("\nâœ… Federated training complete!")
        print("ğŸ“ Model saved: models/federated_model.pth")
    
    def evaluate(self, data):
        """è¯„ä¼°å…¨å±€æ¨¡å‹"""
        self.global_model.eval()
        correct = 0
        
        with torch.no_grad():
            for item in data:
                graphs = item['graphs']
                label = torch.tensor([item['label']], dtype=torch.long).to(device)
                
                batch_ast = torch.zeros(graphs['ast'].x.size(0), dtype=torch.long).to(device)
                batch_cfg = torch.zeros(graphs['cfg'].x.size(0), dtype=torch.long).to(device)
                batch_dfg = torch.zeros(graphs['dfg'].x.size(0), dtype=torch.long).to(device)
                batch_pdg = torch.zeros(graphs['pdg'].x.size(0), dtype=torch.long).to(device)
                
                for g_type in graphs:
                    graphs[g_type] = graphs[g_type].to(device)
                
                out = self.global_model(graphs['ast'], graphs['cfg'], graphs['dfg'], graphs['pdg'],
                                       (batch_ast, batch_cfg, batch_dfg, batch_pdg))
                pred = out.argmax(dim=1)
                correct += (pred == label).sum().item()
        
        return correct / len(data) if len(data) > 0 else 0


def main():
    trainer = FederatedTrainer(num_clients=5, rounds=20)
    trainer.train()


if __name__ == "__main__":
    Path("models").mkdir(exist_ok=True)
    main()